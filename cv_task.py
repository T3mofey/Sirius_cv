# -*- coding: utf-8 -*-
"""cv_task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jcnk3ZH0x43G132o504-wl7N3uY5BR1y
"""

from transformers import pipeline
pipe = pipeline("image-segmentation", model="briaai/RMBG-1.4", trust_remote_code=True)

import torch
from transformers import AutoModelForImageSegmentation
from torchvision.transforms.functional import normalize
model = AutoModelForImageSegmentation.from_pretrained("briaai/RMBG-1.4",trust_remote_code=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
torch.cuda.empty_cache()
print(device)

"""Аугментация данных(крутить, замылить и тд)"""

from torchvision import transforms
augmentation=transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.RandomGrayscale(p=0.2),
    transforms.GaussianBlur(kernel_size=(5,5)),
    transforms.ColorJitter(brightness=0.4,contrast=0.4,saturation=0.4,hue=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])
])

"""Закинем данный датасет в даталоудер"""

from torch.utils.data import DataLoader
from torch.utils.data import Dataset
from PIL import Image
import os

folder_dir="/home/timofey/computer_vision/sirius_data"

class CustomImageDataset(Dataset):
    def __init__(self, img_dir, transform=None):
        self.img_dir = img_dir
        self.transform = transform
        self.image_paths = [os.path.join(self.img_dir, img_name)
                            for img_name in os.listdir(self.img_dir)
                            if img_name.endswith(('jpg', 'png', 'jpeg'))]

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert("RGB")

        if self.transform:
            x1 = self.transform(image)
            x2 = self.transform(image)
        return x1,x2, 0  # Возвращаем 0 в качестве заглушки для меток


dataset=CustomImageDataset(folder_dir,transform=augmentation)
dataload=DataLoader(dataset,batch_size=16,num_workers=2,shuffle=True)

"""Создаем модель BYOL"""


'''import torch
import torch.nn as nn
from lightly.models import BYOL
from torchvision.models import resnet18

resnet = resnet18(pretrained=False)
backbone = nn.Sequential(*list(resnet.children())[:-1])
model_byol=BYOL(backbone,num_ftrs=512,hidden_dim=4096,out_dim=256)

torch.cuda.empty_cache()

from torch import optim
import torch.nn as nn
import torch.nn.functional as F
optimizer=optim.Adam(model_byol.parameters(),lr=1e-4)
criterion=nn.MSELoss()
torch.cuda.empty_cache()
class BYOLLoss(nn.Module):
  def __init__(self):
    super (BYOLLoss,self).__init__()
  def forward(self,x1_loss,x2_loss):
    x1_loss=F.normalize(x1_loss,dim=-1,p=2)
    x2_loss=F.normalize(x2_loss,dim=-1,p=2)
    x2_loss=x2_loss.unsqueeze(-1)
    loss=2-2*(x1_loss*x2_loss.sum(dim=-1))
    return loss.mean()
device=torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_byol=model_byol.to(device)
loss_fn=BYOLLoss()
for epoch in range(100):
  model_byol.train()
  total_loss=0
  for x1,x2,_ in dataload:
    x1=x1.to(device)
    x2=x2.to(device)
    x1_loss,x2_loss=model_byol(x1,x2)
    print(x1_loss)
    loss=loss_fn(x1_loss,x2_loss)
    total_loss+=loss.item()
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
  print(f"number of epoch = {epoch}\t total loss = {total_loss} ")
'''
import os
from os import listdir

arr=[]
folder_dir="/home/timofey/computer_vision/sirius_data"
for image in os.listdir(folder_dir):
  image_path=folder_dir + "/" + image
  try:
    pillow_mask=pipe(image_path,return_mask=True)
    pillow_image=pipe(image_path)
  except Exception as e:
    continue
  print(image)
  arr.append(pillow_image)

#pillow_image = pipe(a) # applies mask on input and returns a pillow image
print(arr)

pillow_image

from transformers import ViTImageProcessor, ViTForImageClassification
from PIL import Image
import requests

url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
image = Image.open(requests.get(url, stream=True).raw)

processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')
model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')

inputs = processor(images=image, return_tensors="pt")
outputs = model(**inputs)
logits = outputs.logits
# model predicts one of the 1000 ImageNet classes
predicted_class_idx = logits.argmax(-1).item()
print("Predicted class:", model.config.id2label[predicted_class_idx])


'''import sys
import os
import json

import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import torch
import numpy as np
from PIL import Image
import gc

modelNames={0:"briaai/RMBG-1.4",
            1:"nvidia/segformer-b0-finetuned-ade-512-512",
            2:"ZhengPeng7/BiRefNet"
    }



from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation
from PIL import Image
import requests

processor = SegformerImageProcessor.from_pretrained("nvidia/segformer-b0-finetuned-ade-512-512")
model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b0-finetuned-ade-512-512")

url = "http://images.cocodataset.org/val2017/000000039769.jpg"
image = Image.open(requests.get(url, stream=True).raw)

inputs = processor(images=image, return_tensors="pt")
outputs = model(**inputs)
logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)'''

